{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QSFAlZ2InkdH"
   },
   "source": [
    "## Text Classification\n",
    "In this assignment, your task is to train a ML model for text classification task.\n",
    "\n",
    "Allowed libraries are basic python libraries, numpy, pandas, re, and scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "hyW8Lv3PnkdL"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import collections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0ccRvrZ-nkdN"
   },
   "source": [
    "# Q1\n",
    "## Data Collection and Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F_-mdlGMnkdP"
   },
   "source": [
    "a) Download the 'tweeteval' emotion dataset from https://huggingface.co/datasets/tweet_eval/tree/main/dummy/emotion/1.1.0 and read the training corpus with $pandas$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "i5B-X5iankdP",
    "outputId": "58a468a9-c9b8-4acb-c08f-5d06b876e92f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-21959fc5-1845-4e78-b3f0-18bada722799\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>“Worry is a down payment on a problem you may ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>My roommate: it's okay that we can't spell bec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>No but that's so cute. Atsu was probably shy a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Rooneys fucking untouchable isn't he? Been fuc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>it's pretty depressing when u hit pan on ur fa...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-21959fc5-1845-4e78-b3f0-18bada722799')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-21959fc5-1845-4e78-b3f0-18bada722799 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-21959fc5-1845-4e78-b3f0-18bada722799');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "                                                text\n",
       "0  “Worry is a down payment on a problem you may ...\n",
       "1  My roommate: it's okay that we can't spell bec...\n",
       "2  No but that's so cute. Atsu was probably shy a...\n",
       "3  Rooneys fucking untouchable isn't he? Been fuc...\n",
       "4  it's pretty depressing when u hit pan on ur fa..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# code\n",
    "df = pd.read_csv('dummy_data/train_text.txt', sep='\\t', header=None)\n",
    "df.columns = ['text']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "srwUEfS8nkdS"
   },
   "source": [
    "b) Lowercase the text in the training courpus and then use Spacy to tokenize and lemmatize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "D6LwhrD7nkdV",
    "outputId": "0d609d01-4274-4d62-d736-1debab954870"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-3f857957-dcbf-499d-99a2-3254a7960f9b\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[\", worry, be, a, down, payment, on, a, proble...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[my, roommate, :, it, be, okay, that, we, can,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[no, but, that, be, so, cute, ., atsu, be, pro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[rooney, fuck, untouchable, be, not, he, ?, be...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[it, be, pretty, depressing, when, u, hit, pan...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3f857957-dcbf-499d-99a2-3254a7960f9b')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-3f857957-dcbf-499d-99a2-3254a7960f9b button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-3f857957-dcbf-499d-99a2-3254a7960f9b');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "                                                text\n",
       "0  [\", worry, be, a, down, payment, on, a, proble...\n",
       "1  [my, roommate, :, it, be, okay, that, we, can,...\n",
       "2  [no, but, that, be, so, cute, ., atsu, be, pro...\n",
       "3  [rooney, fuck, untouchable, be, not, he, ?, be...\n",
       "4  [it, be, pretty, depressing, when, u, hit, pan..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "df['text'] = df['text'].str.lower()\n",
    "df['text'] = df['text'].apply(lambda x: [token.lemma_ for token in nlp(x)])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "53e6WRTVnkdW"
   },
   "source": [
    "c) Build a vocabulary after removing (i) stop words, (ii) punctuation marks and symbols,  and (iii) the words with frequence 2 or less. To find the stop words, sort the words by their count in descending order and identify manually the words not related to \"emotion\". You can only use basic python and regular expression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "IxmjhiFMnkdX"
   },
   "outputs": [],
   "source": [
    "stopwords = [\n",
    "    'a', 'about', 'above', 'after', 'again', 'against', 'all', 'am', 'an', 'and', 'any', 'are', \"aren't\", 'as', 'at', 'be',\n",
    "    'because', 'been', 'before', 'being', 'below', 'between', 'both', 'but', 'by', \"can't\", 'cannot', 'could', \"couldn't\",\n",
    "    'did', \"didn't\", 'do', 'does', \"doesn't\", 'doing', \"don't\", 'down', 'during', 'each', 'few', 'for', 'from', 'further',\n",
    "    'had', \"hadn't\", 'has', \"hasn't\", 'have', \"haven't\", 'having', 'he', \"he'd\", \"he'll\", \"he's\", 'her', 'here', \"here's\",\n",
    "    'hers', 'herself', 'him', 'himself', 'his', 'how', \"how's\", 'i', \"i'd\", \"i'll\", \"i'm\", \"i've\", 'if', 'in', 'into', 'is',\n",
    "    \"isn't\", 'it', \"it's\", 'its', 'itself', \"let's\", 'me', 'more', 'most', \"mustn't\", 'my', 'myself', 'no', 'nor', 'not',\n",
    "    'of', 'off', 'on', 'once', 'only', 'or', 'other', 'ought', 'our', 'ours', 'ourselves', 'out', 'over', 'own', 'same',\n",
    "    \"shan't\", 'she', \"she'd\", \"she'll\", \"she's\", 'should', \"shouldn't\", 'so', 'some', 'such', 'than', 'that', \"that's\",\n",
    "    'the', 'their', 'theirs', 'them', 'themselves', 'then', 'there', \"there's\", 'these', 'they', \"they'd\", \"they'll\",\n",
    "    \"they're\", \"they've\", 'this', 'those', 'through', 'to', 'too', 'under', 'until', 'up', 'very', 'was', \"wasn't\", 'we',\n",
    "    \"we'd\", \"we'll\", \"we're\", \"we've\", 'were', \"weren't\", 'what', \"what's\", 'when', \"when's\", 'where', \"where's\", 'which',\n",
    "    'while', 'who', \"who's\", 'whom', 'why', \"why's\", 'with', \"won't\", 'would', \"wouldn't\", 'you', \"you'd\", \"you'll\",\n",
    "    \"you're\", \"you've\", 'your', 'yours', 'yourself', 'yourselves'\n",
    "    \n",
    "]\n",
    "\n",
    "# remove punctuation marks and symbols using regex\n",
    "df['text'] = df['text'].apply(lambda x: [re.sub(r'[^\\w\\s]','',word) for word in x])\n",
    "\n",
    "# remove stop words\n",
    "df['text'] = df['text'].apply(lambda x: [word for word in x if word not in stopwords])\n",
    "\n",
    "# remove words with frequency 2 or less\n",
    "freq = pd.Series(' '.join(df['text'].astype(str)).split()).value_counts()\n",
    "freq = freq[freq <= 2]\n",
    "df['text'] = df['text'].apply(lambda x: [token for token in x if token not in freq])\n",
    "\n",
    "\n",
    "# remove empty strings\n",
    "df['text'] = df['text'].apply(lambda x: [token for token in x if token != ''])\n",
    "\n",
    "# sort the words by their count in descending order\n",
    "freq = pd.Series(' '.join(df['text'].astype(str)).split()).value_counts()\n",
    "freq = freq.sort_values(ascending=False)\n",
    "freq\n",
    "\n",
    "# build the vocabulary\n",
    "vocab = freq.index.tolist()\n",
    "vocab\n",
    "\n",
    "\n",
    "\n",
    "# save the vocabulary\n",
    "with open('vocabularies.txt', 'w') as f:\n",
    "    for item in vocab:\n",
    "        f.write(\"%s \" % item)\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lCBwVM6MnkdZ"
   },
   "source": [
    "d) Consider words in the vocabulary as features and convert each sample/text to a bag or word represetnation. This will be your training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "tgPTQ97JnkdZ",
    "outputId": "706db92a-102c-427f-ba79-41083679b6fa"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-5dba90c8-c7b2-47b0-bc76-d299dc92024e\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5dba90c8-c7b2-47b0-bc76-d299dc92024e')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-5dba90c8-c7b2-47b0-bc76-d299dc92024e button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-5dba90c8-c7b2-47b0-bc76-d299dc92024e');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "                                                text\n",
       "0  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
       "1  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
       "2  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
       "3  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
       "4  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('vocabularies.txt', 'r') as f:\n",
    "    vocabularies = f.read().split()\n",
    "\n",
    "# convert each sample/text to a bag or word represetnation\n",
    "def convert_to_bow(text):\n",
    "    bow = np.zeros(len(vocabularies))\n",
    "    for word in text:\n",
    "        if word in vocabularies:\n",
    "            bow[vocabularies.index(word)] += 1\n",
    "    return bow\n",
    "\n",
    "df['text'] = df['text'].apply(lambda x: convert_to_bow(x))\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3vI1RLMfnkda"
   },
   "source": [
    "e) Repeat steps (a), (b), and (d) for test corpus to obtain the test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "P-0qEHNxnkda",
    "outputId": "93384aad-ad19-43da-bb2a-f26bc513a686"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"'I',\",\n",
       " \"['user',\",\n",
       " \"'user',\",\n",
       " \"'\",\n",
       " \"['I',\",\n",
       " \"',\",\n",
       " \"'get',\",\n",
       " \"']\",\n",
       " \"'just',\",\n",
       " \"'can',\",\n",
       " \"'make',\",\n",
       " \"'like',\",\n",
       " \"'will',\",\n",
       " \"'go',\",\n",
       " \"'amp',\",\n",
       " \"'know',\",\n",
       " \"'love',\",\n",
       " \"'say',\",\n",
       " \"'need',\",\n",
       " \"'one',\",\n",
       " \"'people',\",\n",
       " \"'day',\",\n",
       " \"'u',\",\n",
       " \"'s',\",\n",
       " \"'look',\",\n",
       " \"'feel',\",\n",
       " \"'time',\",\n",
       " \"'see',\",\n",
       " \"'think',\",\n",
       " \"'want',\",\n",
       " \"'now',\",\n",
       " \"'still',\",\n",
       " \"'good',\",\n",
       " \"'really',\",\n",
       " \"'even',\",\n",
       " \"'thing',\",\n",
       " \"'back',\",\n",
       " \"'ve',\",\n",
       " \"'never',\",\n",
       " \"'start',\",\n",
       " \"'much',\",\n",
       " \"'happy',\",\n",
       " \"'come',\",\n",
       " \"'let',\",\n",
       " \"'work',\",\n",
       " \"'today',\",\n",
       " \"'take',\",\n",
       " \"'well',\",\n",
       " \"'fear',\",\n",
       " \"'bad',\",\n",
       " \"'try',\",\n",
       " \"'use',\",\n",
       " \"'user']\",\n",
       " \"'someone',\",\n",
       " \"'year',\",\n",
       " \"'sad',\",\n",
       " \"'laugh',\",\n",
       " \"'help',\",\n",
       " \"'m',\",\n",
       " \"'cry',\",\n",
       " \"'leave',\",\n",
       " \"'shit',\",\n",
       " \"'ur',\",\n",
       " \"'man',\",\n",
       " \"'lose',\",\n",
       " \"'watch',\",\n",
       " \"'great',\",\n",
       " \"'world',\",\n",
       " \"'night',\",\n",
       " \"'smile',\",\n",
       " \"'ever',\",\n",
       " \"'stop',\",\n",
       " \"'2',\",\n",
       " \"'last',\",\n",
       " \"'big',\",\n",
       " \"'first',\",\n",
       " \"'many',\",\n",
       " \"'funny',\",\n",
       " \"'rage',\",\n",
       " \"'sleep',\",\n",
       " \"'hope',\",\n",
       " \"'call',\",\n",
       " \"'way',\",\n",
       " \"'life',\",\n",
       " \"'talk',\",\n",
       " \"'keep',\",\n",
       " \"'hate',\",\n",
       " \"'right',\",\n",
       " \"'amazing',\",\n",
       " \"'terrorism',\",\n",
       " \"'bully',\",\n",
       " \"'give',\",\n",
       " \"'little',\",\n",
       " \"'hard',\",\n",
       " \"'crap',\",\n",
       " \"'ask',\",\n",
       " \"'new',\",\n",
       " \"'kill',\",\n",
       " \"'trump',\",\n",
       " \"'offend',\",\n",
       " \"'live',\",\n",
       " \"'mean',\",\n",
       " \"'game',\",\n",
       " \"'next',\",\n",
       " \"'show',\",\n",
       " \"'fuck',\",\n",
       " \"'play',\",\n",
       " \"'always',\",\n",
       " \"'n',\",\n",
       " \"'birthday',\",\n",
       " \"'I']\",\n",
       " \"'hear',\",\n",
       " \"'break',\",\n",
       " \"'sad']\",\n",
       " \"'around',\",\n",
       " \"'miss',\",\n",
       " \"'attack',\",\n",
       " \"'terror',\",\n",
       " \"'afraid',\",\n",
       " \"'oh',\",\n",
       " \"'happen',\",\n",
       " \"'real',\",\n",
       " \"'something',\",\n",
       " \"'god',\",\n",
       " \"'tell',\",\n",
       " \"['can',\",\n",
       " \"'hold',\",\n",
       " \"'old',\",\n",
       " \"'revenge',\",\n",
       " \"'outrage',\",\n",
       " \"'heart',\",\n",
       " \"'without',\",\n",
       " \"'worry',\",\n",
       " \"'angry',\",\n",
       " \"'actually',\",\n",
       " \"'please',\",\n",
       " \"'stay',\",\n",
       " \"['one',\",\n",
       " \"'find',\",\n",
       " \"'rage']\",\n",
       " \"'anger',\",\n",
       " \"'thank',\",\n",
       " \"'read',\",\n",
       " \"'mad',\",\n",
       " \"'dream',\",\n",
       " \"'cause',\",\n",
       " \"'hatred',\",\n",
       " \"'another',\",\n",
       " \"'kid',\",\n",
       " \"'4',\",\n",
       " \"'wait',\",\n",
       " \"'may',\",\n",
       " \"'hour',\",\n",
       " \"'spend',\",\n",
       " \"'friend',\",\n",
       " \"'every',\",\n",
       " \"'w',\",\n",
       " \"'dark',\",\n",
       " \"'wrong',\",\n",
       " \"'face',\",\n",
       " \"'eclipse',\",\n",
       " \"'terrible',\",\n",
       " \"'5',\",\n",
       " \"'fume',\",\n",
       " \"'die',\",\n",
       " \"'though',\",\n",
       " \"'angry']\",\n",
       " \"'money',\",\n",
       " \"'us',\",\n",
       " \"'serious',\",\n",
       " \"'turn',\",\n",
       " \"'anything',\",\n",
       " \"'point',\",\n",
       " \"'place',\",\n",
       " \"'lol',\",\n",
       " \"'joke',\",\n",
       " \"'sound',\",\n",
       " \"'r',\",\n",
       " \"'become',\",\n",
       " \"'word',\",\n",
       " \"'end',\",\n",
       " \"'snap',\",\n",
       " \"'dread',\",\n",
       " \"'burn',\",\n",
       " \"'long',\",\n",
       " \"'home',\",\n",
       " \"'enough',\",\n",
       " \"'sorry',\",\n",
       " \"'tear',\",\n",
       " \"'bc',\",\n",
       " \"'put',\",\n",
       " \"'depression',\",\n",
       " \"'week',\",\n",
       " \"'ha',\",\n",
       " \"'fucking',\",\n",
       " \"'horrible',\",\n",
       " \"'feeling',\",\n",
       " \"'person',\",\n",
       " \"'awful',\",\n",
       " \"'dog',\",\n",
       " \"'change',\",\n",
       " \"['just',\",\n",
       " \"['people',\",\n",
       " \"'bit',\",\n",
       " \"'run',\",\n",
       " \"'awesome',\",\n",
       " \"'burst',\",\n",
       " \"'tonight',\",\n",
       " \"'job',\",\n",
       " \"['good',\",\n",
       " \"'buy',\",\n",
       " \"'wanna',\",\n",
       " \"['happy',\",\n",
       " \"'anxiety',\",\n",
       " \"'cheer',\",\n",
       " \"'everyone',\",\n",
       " \"'girl',\",\n",
       " \"'outrage']\",\n",
       " \"'twitter',\",\n",
       " \"'7',\",\n",
       " \"'online',\",\n",
       " \"'fume']\",\n",
       " \"'throw',\",\n",
       " \"'threat',\",\n",
       " \"'order',\",\n",
       " \"'follow',\",\n",
       " \"'service',\",\n",
       " \"'baby',\",\n",
       " \"'intimidate',\",\n",
       " \"'concern',\",\n",
       " \"'pay',\",\n",
       " \"'head',\",\n",
       " \"'sadness',\",\n",
       " \"['will',\",\n",
       " \"'sadness']\",\n",
       " \"'smile']\",\n",
       " \"'drink',\",\n",
       " \"'move',\",\n",
       " \"'maybe',\",\n",
       " \"'government',\",\n",
       " \"'nervous',\",\n",
       " \"'month',\",\n",
       " \"'also',\",\n",
       " \"'two',\",\n",
       " \"'3',\",\n",
       " \"'woman',\",\n",
       " \"'full',\",\n",
       " \"'shake',\",\n",
       " \"'adorable',\",\n",
       " \"'cry']\",\n",
       " \"'whole',\",\n",
       " \"'believe',\",\n",
       " \"'literally',\",\n",
       " \"'guy',\",\n",
       " \"'fact',\",\n",
       " \"'death',\",\n",
       " \"'might',\",\n",
       " \"'depressed',\",\n",
       " \"'excited',\",\n",
       " \"'mom',\",\n",
       " \"'horrific',\",\n",
       " \"'hilarious',\",\n",
       " \"'terrify',\",\n",
       " \"'wake',\",\n",
       " \"'team',\",\n",
       " \"'probably',\",\n",
       " \"'free',\",\n",
       " \"'rabid',\",\n",
       " \"'anxiety']\",\n",
       " \"'news',\",\n",
       " \"'learn',\",\n",
       " \"'poor',\",\n",
       " \"'nothing',\",\n",
       " \"'furious',\",\n",
       " \"'rest',\",\n",
       " \"'seem',\",\n",
       " \"'pic',\",\n",
       " \"'beautiful',\",\n",
       " \"'one']\",\n",
       " \"'book',\",\n",
       " \"['today',\",\n",
       " \"'instead',\",\n",
       " \"'snapchat',\",\n",
       " \"'write',\",\n",
       " \"'moment',\",\n",
       " \"'happiness',\",\n",
       " \"'hilarious']\",\n",
       " \"'awful']\",\n",
       " \"'ass',\",\n",
       " \"'customer',\",\n",
       " \"'soul',\",\n",
       " \"'blue',\",\n",
       " \"'video',\",\n",
       " \"'bitter',\",\n",
       " \"'ticket',\",\n",
       " \"'irritate',\",\n",
       " \"'panic',\",\n",
       " \"'send',\",\n",
       " \"'away',\",\n",
       " \"'laughter',\",\n",
       " \"'yeah',\",\n",
       " \"'america',\",\n",
       " \"'hair',\",\n",
       " \"'yet',\",\n",
       " \"'speak',\",\n",
       " \"'day']\",\n",
       " \"'1',\",\n",
       " \"'lot',\",\n",
       " \"'pain',\",\n",
       " \"'wonder',\",\n",
       " \"'tomorrow',\",\n",
       " \"'despair',\",\n",
       " \"'soon',\",\n",
       " \"'meet',\",\n",
       " \"'eye',\",\n",
       " \"'safe',\",\n",
       " \"'bring',\",\n",
       " \"'remember',\",\n",
       " \"'already',\",\n",
       " \"'tantrum']\",\n",
       " \"'tv',\",\n",
       " \"'episode',\",\n",
       " \"'furious']\",\n",
       " \"'child',\",\n",
       " \"'10',\",\n",
       " \"'alone',\",\n",
       " \"'red',\",\n",
       " \"'irritated']\",\n",
       " \"'reason',\",\n",
       " \"'wrath',\",\n",
       " \"'folk',\",\n",
       " \"'eat',\",\n",
       " \"'movie',\",\n",
       " \"'matter',\",\n",
       " \"'stupid',\",\n",
       " \"'low',\",\n",
       " \"'stand',\",\n",
       " \"'action',\",\n",
       " \"'hurt',\",\n",
       " \"'light',\",\n",
       " \"'re',\",\n",
       " \"'sign',\",\n",
       " \"'seriously',\",\n",
       " \"'hand',\",\n",
       " \"'lol']\",\n",
       " \"'cute',\",\n",
       " \"'sure',\",\n",
       " \"'depress']\",\n",
       " \"'jr',\",\n",
       " \"'hot',\",\n",
       " \"['love',\",\n",
       " \"'well']\",\n",
       " \"'left',\",\n",
       " \"'fun',\",\n",
       " \"['every',\",\n",
       " \"'super',\",\n",
       " \"'add',\",\n",
       " \"'horror',\",\n",
       " \"'scared',\",\n",
       " \"'chat',\",\n",
       " \"'india',\",\n",
       " \"'understand',\",\n",
       " \"['go',\",\n",
       " \"'able',\",\n",
       " \"'state',\",\n",
       " \"'quote',\",\n",
       " \"'amount',\",\n",
       " \"'support',\",\n",
       " \"'6',\",\n",
       " \"'depression']\",\n",
       " \"'family',\",\n",
       " \"'brother',\",\n",
       " \"'president',\",\n",
       " \"'hell',\",\n",
       " \"'morning',\",\n",
       " \"'lead',\",\n",
       " \"'grateful',\",\n",
       " \"'optimism',\",\n",
       " \"'experience',\",\n",
       " \"'local',\",\n",
       " \"'kind',\",\n",
       " \"'close',\",\n",
       " \"'ago',\",\n",
       " \"'second',\",\n",
       " \"['get',\",\n",
       " \"'post',\",\n",
       " \"'sir',\",\n",
       " \"'strike',\",\n",
       " \"'star',\",\n",
       " \"'everything',\",\n",
       " \"'almost',\",\n",
       " \"'mind',\",\n",
       " \"'return',\",\n",
       " \"'ppl',\",\n",
       " \"'boy',\",\n",
       " \"'sink',\",\n",
       " \"'shock',\",\n",
       " \"'class',\",\n",
       " \"'ready',\",\n",
       " \"'care',\",\n",
       " \"'wear',\",\n",
       " \"'damn',\",\n",
       " \"'fury',\",\n",
       " \"'dead',\",\n",
       " \"'name',\",\n",
       " \"'crap']\",\n",
       " \"['try',\",\n",
       " \"'depressed']\",\n",
       " \"'dress',\",\n",
       " \"'food',\",\n",
       " \"['look',\",\n",
       " \"'piss',\",\n",
       " \"'enjoy',\",\n",
       " \"['think',\",\n",
       " \"'else',\",\n",
       " \"['ever',\",\n",
       " \"'insult']\",\n",
       " \"'train',\",\n",
       " \"'man']\",\n",
       " \"'sadly',\",\n",
       " \"'ex',\",\n",
       " \"'walk',\",\n",
       " \"'nightmare']\",\n",
       " \"'choose',\",\n",
       " \"'afraid']\",\n",
       " \"'sale',\",\n",
       " \"'james',\",\n",
       " \"'alarm',\",\n",
       " \"'bed',\",\n",
       " \"'offense',\",\n",
       " \"'true',\",\n",
       " \"['feel',\",\n",
       " \"'disappointing',\",\n",
       " \"'character',\",\n",
       " \"'time']\",\n",
       " \"'leg',\",\n",
       " \"'glad',\",\n",
       " \"'dick',\",\n",
       " \"'upset',\",\n",
       " \"'lyft',\",\n",
       " \"'earth',\",\n",
       " \"'grow',\",\n",
       " \"'phone',\",\n",
       " \"'annoyed',\",\n",
       " \"'express',\",\n",
       " \"'sell',\",\n",
       " \"'power',\",\n",
       " \"'college',\",\n",
       " \"'yes',\",\n",
       " \"'wonderful',\",\n",
       " \"'weary',\",\n",
       " \"'rejoice',\",\n",
       " \"'smoke',\",\n",
       " \"'gloomy',\",\n",
       " \"'scare',\",\n",
       " \"'part',\",\n",
       " \"'ugh',\",\n",
       " \"'since',\",\n",
       " \"'feed',\",\n",
       " \"['know',\",\n",
       " \"'park',\",\n",
       " \"'continue',\",\n",
       " \"'bright',\",\n",
       " \"['us',\",\n",
       " \"'depressing',\",\n",
       " \"'tweet',\",\n",
       " \"'finally',\",\n",
       " \"'early',\",\n",
       " \"'body',\",\n",
       " \"'delicious']\",\n",
       " \"'nice',\",\n",
       " \"'weather',\",\n",
       " \"'grudge',\",\n",
       " \"'today']\",\n",
       " \"'type',\",\n",
       " \"'bad']\",\n",
       " \"['let',\",\n",
       " \"'pm',\",\n",
       " \"'mourn',\",\n",
       " \"'sit',\",\n",
       " \"'scare']\",\n",
       " \"['oh',\",\n",
       " \"'past',\",\n",
       " \"'question',\",\n",
       " \"'near',\",\n",
       " \"'crow',\",\n",
       " \"'need']\",\n",
       " \"['thing',\",\n",
       " \"['time',\",\n",
       " \"'stuff',\",\n",
       " \"'half',\",\n",
       " \"'car',\",\n",
       " \"'hesitate',\",\n",
       " \"'piss']\",\n",
       " \"'list',\",\n",
       " \"'ridiculous',\",\n",
       " \"'c',\",\n",
       " \"'code',\",\n",
       " \"'puss',\",\n",
       " \"'hey',\",\n",
       " \"'delicious',\",\n",
       " \"'suppose',\",\n",
       " \"'bless']\",\n",
       " \"'price',\",\n",
       " \"'far',\",\n",
       " \"'together',\",\n",
       " \"'voice',\",\n",
       " \"'insecure',\",\n",
       " \"'sense',\",\n",
       " \"'evening',\",\n",
       " \"'city',\",\n",
       " \"['really',\",\n",
       " \"'finish',\",\n",
       " \"'thought',\",\n",
       " \"'air',\",\n",
       " \"'v',\",\n",
       " \"['wow',\",\n",
       " \"'sister',\",\n",
       " \"'jump',\",\n",
       " \"'g',\",\n",
       " \"'tbh',\",\n",
       " \"'omg',\",\n",
       " \"'restless',\",\n",
       " \"'forget',\",\n",
       " \"'fair',\",\n",
       " \"'allow',\",\n",
       " \"'threaten',\",\n",
       " \"'love']\",\n",
       " \"'fan',\",\n",
       " \"['sad',\",\n",
       " \"'cool',\",\n",
       " \"'optimism']\",\n",
       " \"'boring',\",\n",
       " \"'dem',\",\n",
       " \"'fire',\",\n",
       " \"['omg',\",\n",
       " \"'choice',\",\n",
       " \"'mouth',\",\n",
       " \"'family']\",\n",
       " \"'truly',\",\n",
       " \"'silence',\",\n",
       " \"'depress',\",\n",
       " \"'wtf',\",\n",
       " \"'pathetic',\",\n",
       " \"'giggle']\",\n",
       " \"'tired',\",\n",
       " \"'horrid',\",\n",
       " \"'exactly',\",\n",
       " \"'mistake',\",\n",
       " \"['take',\",\n",
       " \"'piece',\",\n",
       " \"'fake',\",\n",
       " \"'win',\",\n",
       " \"'problem',\",\n",
       " \"'fund',\",\n",
       " \"['moment',\",\n",
       " \"'fill',\",\n",
       " \"'message',\",\n",
       " \"'dreadful']\",\n",
       " \"'insult',\",\n",
       " \"'hillary',\",\n",
       " \"'awake',\",\n",
       " \"'nightmare',\",\n",
       " \"'issue',\",\n",
       " \"'grim']\",\n",
       " \"'bitch',\",\n",
       " \"'provocation',\",\n",
       " \"'picture',\",\n",
       " \"'getting',\",\n",
       " \"'sun',\",\n",
       " \"'fear']\",\n",
       " \"'upon',\",\n",
       " \"'cream',\",\n",
       " \"'colour',\",\n",
       " \"'least',\",\n",
       " \"'mood',\",\n",
       " \"'\\\\xa0',\",\n",
       " \"'heartbreake']\",\n",
       " \"'trust',\",\n",
       " \"'fuel',\",\n",
       " \"'people']\",\n",
       " \"['well',\",\n",
       " \"'annoy',\",\n",
       " \"'trip',\",\n",
       " \"'human',\",\n",
       " \"'worth',\",\n",
       " \"'100',\",\n",
       " \"'self',\",\n",
       " \"'boil',\",\n",
       " \"'alive',\",\n",
       " \"'blame',\",\n",
       " \"'short',\",\n",
       " \"'hit',\",\n",
       " \"'decide',\",\n",
       " \"'frown',\",\n",
       " \"'whenever',\",\n",
       " \"'af',\",\n",
       " \"'rip',\",\n",
       " \"'interview',\",\n",
       " \"'terrific',\",\n",
       " \"'deserve',\",\n",
       " \"'station',\",\n",
       " \"'glee']\",\n",
       " \"'tea',\",\n",
       " \"'water',\",\n",
       " \"'black',\",\n",
       " \"'top',\",\n",
       " \"'fall',\",\n",
       " \"'political',\",\n",
       " \"'anyone',\",\n",
       " \"'cloud',\",\n",
       " \"'glee',\",\n",
       " \"'bus',\",\n",
       " \"'bother',\",\n",
       " \"'russia',\",\n",
       " \"'offend']\",\n",
       " \"'music',\",\n",
       " \"'now']\",\n",
       " \"'rather',\",\n",
       " \"'small',\",\n",
       " \"['hey',\",\n",
       " \"'horny',\",\n",
       " \"'bliss',\",\n",
       " \"'b',\",\n",
       " \"'miserable']\",\n",
       " \"'seven',\",\n",
       " \"'annoyed']\",\n",
       " \"'listen',\",\n",
       " \"'defeat',\",\n",
       " \"'record',\",\n",
       " \"'abt',\",\n",
       " \"'8',\",\n",
       " \"'disappointment',\",\n",
       " \"'arrive',\",\n",
       " \"'sexy',\",\n",
       " \"'remind',\",\n",
       " \"'sadly']\",\n",
       " \"'sober',\",\n",
       " \"'sex',\",\n",
       " \"'seat',\",\n",
       " \"'bless',\",\n",
       " \"'must',\",\n",
       " \"'appreciate',\",\n",
       " \"'pretty',\",\n",
       " \"'tremendous',\",\n",
       " \"'pussy',\",\n",
       " \"'happy']\",\n",
       " \"'witness',\",\n",
       " \"'sick',\",\n",
       " \"'hopefully',\",\n",
       " \"'serious']\",\n",
       " \"'smell',\",\n",
       " \"'n']\",\n",
       " \"'sooo',\",\n",
       " \"'see']\",\n",
       " \"'adult',\",\n",
       " \"'enrage',\",\n",
       " \"'night']\",\n",
       " \"'burden',\",\n",
       " \"'wish',\",\n",
       " \"'clear',\",\n",
       " \"'garden',\",\n",
       " \"'ball',\",\n",
       " \"'focused',\",\n",
       " \"'huff',\",\n",
       " \"'idiot',\",\n",
       " \"'revenge']\",\n",
       " \"'50',\",\n",
       " \"'current',\",\n",
       " \"'pine',\",\n",
       " \"'don',\",\n",
       " \"'dude',\",\n",
       " \"'opportunity',\",\n",
       " \"'deeply',\",\n",
       " \"'like']\",\n",
       " \"'screw',\",\n",
       " \"'war',\",\n",
       " \"'blind',\",\n",
       " \"'excellent',\",\n",
       " \"'sea',\",\n",
       " \"'behind',\",\n",
       " \"'lawn',\",\n",
       " \"'pessimist']\",\n",
       " \"'racism',\",\n",
       " \"'beyond',\",\n",
       " \"'o',\",\n",
       " \"'season',\",\n",
       " \"'weapon',\",\n",
       " \"'basically',\",\n",
       " \"'9',\",\n",
       " \"'inspire']\",\n",
       " \"'area',\",\n",
       " \"'wife',\",\n",
       " \"'warn',\",\n",
       " \"'bore',\",\n",
       " \"'sheer',\",\n",
       " \"'dull',\",\n",
       " \"'key',\",\n",
       " \"'release',\",\n",
       " \"'info',\",\n",
       " \"'chirp',\",\n",
       " \"'league',\",\n",
       " \"'cheery',\",\n",
       " \"'satisfied',\",\n",
       " \"'bitterness',\",\n",
       " \"'stick',\",\n",
       " \"'islamic',\",\n",
       " \"'act',\",\n",
       " \"'unhappy']\",\n",
       " \"'awe',\",\n",
       " \"'u']\",\n",
       " \"['hello',\",\n",
       " \"'arsehole']\",\n",
       " \"'deliberate',\",\n",
       " \"'20',\",\n",
       " \"'peace',\",\n",
       " \"'rude',\",\n",
       " \"'holiday',\",\n",
       " \"['come',\",\n",
       " \"'wow',\",\n",
       " \"'origin',\",\n",
       " \"'blessing',\",\n",
       " \"'open',\",\n",
       " \"'door',\",\n",
       " \"'lose']\",\n",
       " \"'affect',\",\n",
       " \"['new',\",\n",
       " \"'scream',\",\n",
       " \"'growl',\",\n",
       " \"'teen',\",\n",
       " \"'laugh']\",\n",
       " \"'22']\",\n",
       " \"'resentment',\",\n",
       " \"'goal',\",\n",
       " \"'aaron',\",\n",
       " \"'side',\",\n",
       " \"'dad',\",\n",
       " \"'shocking',\",\n",
       " \"'purpose',\",\n",
       " \"'huge',\",\n",
       " \"'press',\",\n",
       " \"'cover',\",\n",
       " \"'tremble',\",\n",
       " \"'ste',\",\n",
       " \"'cm',\",\n",
       " \"'cold',\",\n",
       " \"'garbage',\",\n",
       " \"'chicken',\",\n",
       " \"'appear',\",\n",
       " \"'deliver',\",\n",
       " \"'law',\",\n",
       " \"'cnn',\",\n",
       " \"'monster',\",\n",
       " \"'draw',\",\n",
       " \"'front',\",\n",
       " \"'refer',\",\n",
       " \"'test',\",\n",
       " \"'crime',\",\n",
       " \"'modi',\",\n",
       " \"'available',\",\n",
       " \"'ice',\",\n",
       " \"'break']\",\n",
       " \"'interesting',\",\n",
       " \"'country',\",\n",
       " \"'obviously',\",\n",
       " \"'shock']\",\n",
       " \"['nothing',\",\n",
       " \"'datum',\",\n",
       " \"'bet',\",\n",
       " \"'welcome',\",\n",
       " \"'floor',\",\n",
       " \"'decision',\",\n",
       " \"'lazy',\",\n",
       " \"['person',\",\n",
       " \"'forward',\",\n",
       " \"'lack',\",\n",
       " \"['depression',\",\n",
       " \"'fuck']\",\n",
       " \"'clinton',\",\n",
       " \"'trump']\",\n",
       " \"'defense',\",\n",
       " \"'come']\",\n",
       " \"'avoid',\",\n",
       " \"'restless']\",\n",
       " \"'yo',\",\n",
       " \"'authority',\",\n",
       " \"'offer',\",\n",
       " \"'bash',\",\n",
       " \"'stage',\",\n",
       " \"['damn',\",\n",
       " \"'mine',\",\n",
       " \"'special',\",\n",
       " \"'symptom',\",\n",
       " \"'terrified',\",\n",
       " \"'great']\",\n",
       " \"['also',\",\n",
       " \"'streak',\",\n",
       " \"'figure',\",\n",
       " \"'ure',\",\n",
       " \"['amarnathterrorattack',\",\n",
       " \"'somewhere',\",\n",
       " \"'public',\",\n",
       " \"'force',\",\n",
       " \"'crazy',\",\n",
       " \"'tho',\",\n",
       " \"'shift',\",\n",
       " \"'temper',\",\n",
       " \"'security',\",\n",
       " \"'ensure',\",\n",
       " \"'deep',\",\n",
       " \"'personality',\",\n",
       " \"'franchise',\",\n",
       " \"'especially',\",\n",
       " \"'pour',\",\n",
       " \"'kick',\",\n",
       " \"'opinion',\",\n",
       " \"'crush',\",\n",
       " \"'minute',\",\n",
       " \"'want']\",\n",
       " \"'grade',\",\n",
       " \"['say',\",\n",
       " \"'player',\",\n",
       " \"'clearly',\",\n",
       " \"'dumb',\",\n",
       " \"'nearly',\",\n",
       " \"'lay',\",\n",
       " \"'drop',\",\n",
       " \"'breathless',\",\n",
       " \"'brilliant']\",\n",
       " \"'bag',\",\n",
       " \"'crowd',\",\n",
       " \"'plot',\",\n",
       " \"'ring',\",\n",
       " \"['idk',\",\n",
       " \"'d',\",\n",
       " \"'film',\",\n",
       " \"'work']\",\n",
       " \"'disappointing']\",\n",
       " \"'panic']\",\n",
       " \"'account',\",\n",
       " \"'away']\",\n",
       " \"'russian',\",\n",
       " \"'sadden',\",\n",
       " \"'gay',\",\n",
       " \"'gameofthrone',\",\n",
       " \"'seek',\",\n",
       " \"'teach',\",\n",
       " \"'yesterday',\",\n",
       " \"'strong',\",\n",
       " \"'lt3',\",\n",
       " \"'sight',\",\n",
       " \"'include',\",\n",
       " \"'difficult',\",\n",
       " \"['watch',\",\n",
       " \"'anyway',\",\n",
       " \"'nervous']\",\n",
       " \"'back']\",\n",
       " \"'drug',\",\n",
       " \"'relentless']\",\n",
       " \"'quote']\",\n",
       " \"'blow',\",\n",
       " \"'dr',\",\n",
       " \"'award',\",\n",
       " \"'christ',\",\n",
       " \"'12',\",\n",
       " \"'right']\",\n",
       " \"'terrorist',\",\n",
       " \"'announce',\",\n",
       " \"'pop',\",\n",
       " \"'website',\",\n",
       " \"'bottle',\",\n",
       " \"'yummy',\",\n",
       " \"['day',\",\n",
       " \"'assume',\",\n",
       " \"'expect',\",\n",
       " \"'1st',\",\n",
       " \"'yellow',\",\n",
       " \"['see',\",\n",
       " \"'pessimist',\",\n",
       " \"'highly',\",\n",
       " \"'whatever',\",\n",
       " \"'bomb',\",\n",
       " \"'tiny',\",\n",
       " \"'address',\",\n",
       " \"'house',\",\n",
       " \"'hide',\",\n",
       " \"'room']\",\n",
       " \"'son',\",\n",
       " \"'person']\",\n",
       " \"'excitement']\",\n",
       " \"'butt',\",\n",
       " \"'rose',\",\n",
       " \"'bully']\",\n",
       " \"'em',\",\n",
       " \"'member',\",\n",
       " \"'queue',\",\n",
       " \"'less',\",\n",
       " \"'miserable',\",\n",
       " \"'breathe',\",\n",
       " \"'hrc',\",\n",
       " \"'beat',\",\n",
       " \"'agree',\",\n",
       " \"'uk',\",\n",
       " \"'cop',\",\n",
       " \"'jail',\",\n",
       " \"'mother',\",\n",
       " \"'ghost',\",\n",
       " \"'line',\",\n",
       " \"'deal',\",\n",
       " \"'weird',\",\n",
       " \"'brilliant',\",\n",
       " \"'john',\",\n",
       " \"'beautiful']\",\n",
       " \"'cheap',\",\n",
       " \"['work',\",\n",
       " \"['offense',\",\n",
       " \"'delete',\",\n",
       " \"'driver',\",\n",
       " \"'club',\",\n",
       " \"'common',\",\n",
       " \"'insecure']\",\n",
       " \"'fearful',\",\n",
       " \"'rn',\",\n",
       " \"'fight',\",\n",
       " \"'pick',\",\n",
       " \"'despair']\",\n",
       " \"'late',\",\n",
       " \"'complaint',\",\n",
       " \"'waste',\",\n",
       " \"'guess',\",\n",
       " \"'pull',\",\n",
       " \"'game']\",\n",
       " \"'chance',\",\n",
       " \"'muslim',\",\n",
       " \"'card',\",\n",
       " \"'destroy',\",\n",
       " \"'lie',\",\n",
       " \"'american',\",\n",
       " \"'though']\",\n",
       " \"'violence',\",\n",
       " \"'bunch',\",\n",
       " \"'grim',\",\n",
       " \"'idea',\",\n",
       " \"'realize',\",\n",
       " \"'truth',\",\n",
       " \"'avon',\",\n",
       " \"'respect',\",\n",
       " \"'yet']\",\n",
       " \"'separate',\",\n",
       " \"'magical',\",\n",
       " \"'fourth',\",\n",
       " \"'dread']\",\n",
       " \"'relentless',\",\n",
       " \"'shake']\",\n",
       " \"'morata',\",\n",
       " \"'london',\",\n",
       " \"'note',\",\n",
       " \"'appointment',\",\n",
       " \"'fly',\",\n",
       " \"'chelsea',\",\n",
       " \"'stress',\",\n",
       " \"'normal',\",\n",
       " \"'harm',\",\n",
       " \"'sa',\",\n",
       " \"'photooftheday',\",\n",
       " \"'hindu',\",\n",
       " \"['part',\",\n",
       " \"'chase',\",\n",
       " \"'target',\",\n",
       " \"'omg']\",\n",
       " \"'lime',\",\n",
       " \"'kdrama',\",\n",
       " \"'cunt',\",\n",
       " \"'finance',\",\n",
       " \"'wenger',\",\n",
       " \"'turtle',\",\n",
       " \"'angel',\",\n",
       " \"'fashion',\",\n",
       " \"'israel',\",\n",
       " \"'definitely',\",\n",
       " \"'gets',\",\n",
       " \"'vote',\",\n",
       " \"'block',\",\n",
       " \"'european',\",\n",
       " \"'arsehole',\",\n",
       " \"'eu',\",\n",
       " \"'sentiment',\",\n",
       " \"'reaction',\",\n",
       " \"'nope']\",\n",
       " \"'instagood',\",\n",
       " \"'confused',\",\n",
       " \"'urge',\",\n",
       " \"'story']\",\n",
       " \"'obvious',\",\n",
       " \"['u',\",\n",
       " \"'sacrifice',\",\n",
       " \"'brain']\",\n",
       " \"'debut',\",\n",
       " \"'resistance',\",\n",
       " \"'rate',\",\n",
       " ...]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df_test = pd.read_csv('emotion/test_text.txt', sep='\\t', header=None)\n",
    "df_test.columns = ['text']\n",
    "\n",
    "# lowercase the text in the training courpus and then use Spacy to tokenize and lemmatize\n",
    "df_test['text'] = df_test['text'].str.lower()\n",
    "df_test['text'] = df_test['text'].apply(lambda x: [token.lemma_ for token in nlp(x)])\n",
    "\n",
    "# remove punctuation marks and symbols using regex\n",
    "df_test['text'] = df_test['text'].apply(lambda x: [re.sub(r'[^\\w\\s]','',word) for word in x])\n",
    "\n",
    "# remove stop words\n",
    "df_test['text'] = df_test['text'].apply(lambda x: [word for word in x if word not in stopwords])\n",
    "\n",
    "# remove words with frequency 2 or less\n",
    "freq = pd.Series(' '.join(df_test['text'].astype(str)).split()).value_counts()\n",
    "freq = freq[freq <= 2]\n",
    "df_test['text'] = df_test['text'].apply(lambda x: [token for token in x if token not in freq])\n",
    "\n",
    "# remove empty strings\n",
    "df_test['text'] = df_test['text'].apply(lambda x: [token for token in x if token != ''])\n",
    "\n",
    "# sort the words by their count in descending order\n",
    "freq = pd.Series(' '.join(df_test['text'].astype(str)).split()).value_counts()\n",
    "freq = freq.sort_values(ascending=False)\n",
    "\n",
    "# build the vocabulary\n",
    "vocab = freq.index.tolist()\n",
    "vocab\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DYT24n5xnkdb"
   },
   "source": [
    "# Q2 \n",
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "em3nPC_Mnkdc"
   },
   "source": [
    "Train a support vector maching with RBF kernel."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-jy5OSjVnkdc"
   },
   "source": [
    "2a) Do 3-fold cross-validation to pick the optimum $gamma$ hyperparameter in RBF kernel in $sklearn.svm.SVC$.code\n",
    "(https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html). Use \"micro-averaged\" f1-score for test score. \n",
    "\n",
    "See https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html for an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CyOq1agonkdc",
    "outputId": "28d07d94-caed-4f9f-95cb-402304c2c866"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'gamma': 0.001}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# read the training labels\n",
    "df_label = pd.read_csv('emotion/train_labels.txt', sep='\\t', header=None)\n",
    "df_label.columns = ['label']\n",
    "\n",
    "# combine the training data and labels\n",
    "df = pd.concat([df, df_label], axis=1)\n",
    "df.head()\n",
    "\n",
    "# split the training data into 3 folds for cross-validation using n_splits=3\n",
    "from sklearn.model_selection import KFold\n",
    "kf = KFold(n_splits=3, shuffle=True, random_state=42)\n",
    "kf.get_n_splits(df)\n",
    "\n",
    "# pick the optimum gamma hyperparameter in RBF kernel\n",
    "param_grid = {'gamma': [0.001, 0.01, 0.1, 1, 10, 100]}\n",
    "grid = GridSearchCV(SVC(kernel='rbf'), param_grid, cv=kf, scoring='f1_micro')\n",
    "grid.fit(df['text'].tolist(), df['label'].tolist())\n",
    "\n",
    "# print the best parameters\n",
    "print(\"Best parameters: {}\".format(grid.best_params_))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HjD6exYznkdd"
   },
   "source": [
    "b) Plot test score vs gamma. Discuss the gamma values for which the model is underfit and overfit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "id": "Y3nOkifKnkde",
    "outputId": "a63a0b79-d522-4b98-ef30-0911cc800f6f"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# code\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# plot test score vs gamma\n",
    "plt.plot(param_grid['gamma'], grid.cv_results_['mean_test_score'])\n",
    "plt.xlabel('gamma')\n",
    "plt.ylabel('test score')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MvUV_cYYnkde"
   },
   "source": [
    "c) use the best hyperparameter selected in (a) to  train on the entier dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8Uz3a2O-nkde",
    "outputId": "18cbd8a7-0f25-4aea-8654-ca284aca29e3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(gamma=0.001)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# code\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# train on the entier dataset\n",
    "clf = SVC(kernel='rbf', gamma=0.001)\n",
    "clf.fit(df['text'].tolist(), df['label'].tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hAn4Iet3nkdg"
   },
   "source": [
    "# Q3 \n",
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IYBdWFv-nkdg"
   },
   "source": [
    "a) Find the confusion matrix and discuss your observations. Use *sklearn.metrics.confusion_matrix*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "2lrmqz1Cnkdh"
   },
   "outputs": [],
   "source": [
    "# a) Find the confusion matrix and discuss your observations. Use *sklearn.metrics.confusion_matrix*.\n",
    "\n",
    "# code\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# bag of words representation of the test data using the vocabulary from the training data\n",
    "df_test['text'] = df_test['text'].apply(lambda x: convert_to_bow(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "smOGdGfT3lyc"
   },
   "outputs": [],
   "source": [
    "\n",
    "# read the test labels\n",
    "df_test_label = pd.read_csv('emotion/test_labels.txt', sep='\\t', header=None)\n",
    "df_test_label.columns = ['label']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "hsgeTTyZDBUw"
   },
   "outputs": [],
   "source": [
    "\n",
    "#fix feature mismatch before prediction SVC is expecting 8665\n",
    "df_test['text'] = df_test['text'].apply(lambda x: np.append(x, np.zeros(8665-len(x))))\n",
    "\n",
    "# predict the labels\n",
    "y_pred = clf.predict(df_test['text'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sxE1SudnisFH",
    "outputId": "449e63f4-c375-4341-9da4-45cbc70841f5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[558,   0,   0,   0],\n",
       "       [358,   0,   0,   0],\n",
       "       [123,   0,   0,   0],\n",
       "       [382,   0,   0,   0]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# confusion matrix\n",
    "confusion_matrix(df_test_label['label'].tolist(), y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lF66FHAbnkdi"
   },
   "source": [
    "b) Calculate micro-averaged and macro-averaged precision, recall, and F1 score. See the documentation for *sklearn.metrics.f1_score*, *sklearn.metrics.precision_score*, and *sklearn.metrics.recall_score*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tutDjRwHnkdi",
    "outputId": "83b506e6-8a5e-4ec2-cf3c-e8a7b45560ef"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "micro-averaged precision:  0.39268121041520054\n",
      "micro-averaged recall:  0.39268121041520054\n",
      "micro-averaged F1 score:  0.39268121041520054\n"
     ]
    }
   ],
   "source": [
    "# Calculate micro-averaged and macro-averaged precision, recall, and F1 score. See the documentation for *sklearn.metrics.f1_score*, *sklearn.metrics.precision_score*, and *sklearn.metrics.recall_score*.\n",
    "\n",
    "# code\n",
    "\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "\n",
    "# print the micro-averaged precision, recall, and F1 score\n",
    "print('micro-averaged precision: ', precision_score(df_test_label['label'].tolist(), y_pred, average='micro'))\n",
    "print('micro-averaged recall: ', recall_score(df_test_label['label'].tolist(), y_pred, average='micro'))\n",
    "print('micro-averaged F1 score: ', f1_score(df_test_label['label'].tolist(), y_pred, average='micro'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vTxujY1Onkdj"
   },
   "source": [
    "c) Calculate overall accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "v4vw188hnkdk",
    "outputId": "d0a1cdd0-fb91-444c-9fcd-443f5c86ba91"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overall accuracy:  0.39268121041520054\n"
     ]
    }
   ],
   "source": [
    "# Calculate overall accuracy\n",
    "from sklearn.metrics import accuracy_score\n",
    "print('overall accuracy: ', accuracy_score(df_test_label['label'].tolist(), y_pred))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
